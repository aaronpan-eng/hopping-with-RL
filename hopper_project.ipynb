{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the correct packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mujoco\n",
    "import gymnasium as gym\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import os\n",
    "import copy\n",
    "\n",
    "\n",
    "# for copying deep nets to another variable\n",
    "from copy import deepcopy\n",
    "\n",
    "# library for ou noise as implemented with the paper\n",
    "from ou_noise import ou\n",
    "\n",
    "# to view model summary\n",
    "from torchsummary import summary\n",
    "\n",
    "# queue for replay buffer\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, buffer_size):\n",
    "        # initialize parameters\n",
    "        self.buffer_size = buffer_size\n",
    "        self.buffer = deque(maxlen=self.buffer_size)\n",
    "\n",
    "    def insert(self, obs, action, reward, next_obs, done):\n",
    "        # tuple to represent transition\n",
    "        trans = (torch.tensor(obs, dtype=torch.float32), torch.tensor(action, dtype=torch.float32),\n",
    "                 torch.tensor(reward, dtype=torch.float32), torch.tensor(next_obs, dtype=torch.float32), torch.tensor(done, dtype=torch.float32))\n",
    "\n",
    "        # save transition to buffer\n",
    "        # use deque because once its full it discards old items\n",
    "        self.buffer.append(trans)\n",
    "\n",
    "    def sample_random_minibatch(self, batch_size, device):\n",
    "        # Random idx to sample from buffer w/o replacement\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "\n",
    "        # Unpack batch into separate lists of tensors\n",
    "        obs, actions, rewards, next_obs, dones = zip(*batch)\n",
    "        \n",
    "        # Convert lists of tensors into single tensors\n",
    "        obs = torch.stack(obs).to(device)\n",
    "        actions = torch.stack(actions).to(device)\n",
    "        rewards = torch.stack(rewards).to(device)\n",
    "        next_obs = torch.stack(next_obs).to(device)\n",
    "        dones = torch.stack(dones).to(device)\n",
    "\n",
    "        # # convert list to tensor for easy slciing\n",
    "        # batch = torch.tensor(batch)\n",
    "\n",
    "        # # slicing to grab elements\n",
    "        # obs = batch[:,0]\n",
    "        # actions =  batch[:,1]\n",
    "        # rewards = batch[:,2]\n",
    "        # next_obs = batch[:,3]\n",
    "        # dones = batch[:,4]\n",
    "\n",
    "        # tuple of tensors\n",
    "        batch = (obs, actions, rewards, next_obs, dones)\n",
    "\n",
    "        return batch\n",
    "    \n",
    "    # def prepopulate(self, env, actor):\n",
    "    #     # select action from actor\n",
    "    #     # execute action in the env\n",
    "    #     # store transition\n",
    "\n",
    "    #     # intialize state\n",
    "    #     state,_ = env.reset()\n",
    "\n",
    "    #     # loop through num_steps\n",
    "    #     for i in range(self.buffer_size):\n",
    "    #         # choose random action from environment action space (random policy)\n",
    "    #         action = env.action_space.sample()\n",
    "    #         # take action: get next state, reward, done\n",
    "    #         next_state, reward, done, truncate,_ = env.step(action)\n",
    "    #         # add transition to memory\n",
    "    #         self.insert(state, action, reward, next_state, done)\n",
    "\n",
    "    #         # update state\n",
    "    #         if done or truncate:\n",
    "    #             # if truncation reached, reset state\n",
    "    #             state,_ = env.reset()\n",
    "    #         else:\n",
    "    #             # all else state is the next\n",
    "    #             state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING REPLAY BUFFER\n",
    "# test = ReplayBuffer(5)\n",
    "# test.insert(1,1.0,5,2,True)\n",
    "# test.insert(1,1.0,5,2,True)\n",
    "# test.insert(1,1.0,5,2,True)\n",
    "# test.insert(1,1.0,5,2,True)\n",
    "# test.insert(1,1.0,5,2,True)\n",
    "# test.insert(1,1.0,5,2,False)\n",
    "\n",
    "# sample = test.sample_random_minibatch(3)\n",
    "# print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actor AKA: The POLICY\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, num_states, num_actions, hidden_dims=(400,300), init_weight = 3e-3) -> None:\n",
    "        super(Actor, self).__init__()\n",
    "        # In the DDPG paper the parameters for the ACTOR are:\n",
    "        # - Learning rate: 10^-4\n",
    "        # - 2 hidden layers\n",
    "        # - 400 & 300 hidden dims (called units in paper) for first and second hidden layer, respectively\n",
    "        # - ReLU (rectified nonlinearity) for all hidden layers\n",
    "        # - output layer uses tanh (returns actions needed for the agent)\n",
    "\n",
    "        # initializing layer weights\n",
    "        # - hidden layers weights iniitalized with uniform distribution (-1/sqrt(fan_in), 1/sqrt(fan_in)); fan_in being the input of that particular layer\n",
    "        # - output layer weights initialized with uniform distribution (-3e-3,3e-3)\n",
    "        self.init_weight_limit = init_weight\n",
    "\n",
    "        # hidden layers\n",
    "        self.hidden1 = nn.Linear(num_states, hidden_dims[0]) # input to hidden\n",
    "        self.hidden2 = nn.Linear(hidden_dims[0], hidden_dims[1]) # hidden to hidden\n",
    "        # output layer\n",
    "        self.output = nn.Linear(hidden_dims[1], num_actions) # hidden to output\n",
    "        # activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        # initialize weights\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # input to first hidden layer w/ relu activation\n",
    "        x = self.hidden1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # feed into second hidden layer w/ relu activation\n",
    "        x = self.hidden2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # feed through output layer w/ tanh activation\n",
    "        x = self.output(x)\n",
    "        y = self.tanh(x)\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def init_weights(self):\n",
    "        # init hidden with uniform distribution (-1/sqrt(fan_in), 1/sqrt(fan_in)); fan_in being the input of that particular layer\n",
    "        self.hidden1.weight.data.uniform_(-(1/math.sqrt(self.hidden1.weight.size(1))),(1/math.sqrt(self.hidden1.weight.size(1))))\n",
    "        self.hidden2.weight.data.uniform_(-(1/math.sqrt(self.hidden2.weight.size(1))),(1/math.sqrt(self.hidden2.weight.size(1))))\n",
    "        # output layer weights init with uniform distribution (-3e-3,3e-3)\n",
    "        self.output.weight.data.uniform_(-self.init_weight_limit, self.init_weight_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critic AKA: The Q-VALUE FUNCTION\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, num_states, num_actions, output_dim=1, hidden_dims=(400,300), init_weight = 3e-3) -> None:\n",
    "        super(Critic, self).__init__()\n",
    "        # In the DDPG paper the parameters for the CRITIC are:\n",
    "        # - Learning rate: 10^-3\n",
    "        # - 2 hidden layers\n",
    "        # - 400 & 300 hidden dims (called units in paper) for first and second hidden layer, respectively\n",
    "        # - ReLU (rectified nonlinearity) for all hidden layers\n",
    "        # - output layer uses tanh (returns a single q-value for the input state-action pair)\n",
    "        # - output layer weights initialized with uniform distribution (low=-3e-3,high=3e-3)\n",
    "\n",
    "        # initializing layer weights\n",
    "        # - hidden layers weights iniitalized with uniform distribution (-1/sqrt(fan_in), 1/sqrt(fan_in)); fan_in being the input of that particular layer\n",
    "        # - output layer weights initialized with uniform distribution (-3e-3,3e-3)\n",
    "        self.init_weight_limit = init_weight\n",
    "\n",
    "        # hidden layers\n",
    "        self.hidden1 = nn.Linear(num_states, hidden_dims[0]) # input to hidden, nn.Linear are the next layers after the given input x\n",
    "        self.hidden2 = nn.Linear(hidden_dims[0]+num_actions, hidden_dims[1]) # hidden to hidden\n",
    "        # output layer\n",
    "        self.output = nn.Linear(hidden_dims[1], output_dim) # hidden to output\n",
    "        # activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        # initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # pull state and action from input\n",
    "        state, action = x\n",
    "\n",
    "        # first hidden layer and relu activation\n",
    "        x = self.hidden1(state)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # in critic (Q-value fn) network, the actions are not included until the second hidden layer\n",
    "        # feed thru w/ relu activation\n",
    "        x = self.hidden2(torch.cat([x,action],1))\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # feed through output layer w/ tanh activation\n",
    "        x = self.output(x)\n",
    "        y = self.tanh(x)\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def init_weights(self):\n",
    "        # init hidden with uniform distribution (-1/sqrt(fan_in), 1/sqrt(fan_in)); fan_in being the input of that particular layer\n",
    "        # alternative method: nn.init.uniform_(self.hidden1.weight, a=-(1/math.sqrt(self.hidden1.weight.size(1))), b=(1/math.sqrt(self.hidden1.weight.size(1))))\n",
    "        self.hidden1.weight.data.uniform_(-(1/math.sqrt(self.hidden1.weight.size(1))),(1/math.sqrt(self.hidden1.weight.size(1))))\n",
    "        self.hidden2.weight.data.uniform_(-(1/math.sqrt(self.hidden2.weight.size(1))),(1/math.sqrt(self.hidden2.weight.size(1))))\n",
    "        # output layer weights init with uniform distribution (-3e-3,3e-3)\n",
    "        self.output.weight.data.uniform_(-self.init_weight_limit, self.init_weight_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [reference] https://github.com/udacity/deep-reinforcement-learning/blob/master/ddpg-bipedal/ddpg_agent.py\n",
    "# Used Udacity tutorial for OU noise generation\n",
    "class OUNoise:\n",
    "    \"\"\"Ornstein-Uhlenbeck process.\"\"\"\n",
    "\n",
    "    def __init__(self, size, seed, mu=0., theta=0.15, sigma=0.2):\n",
    "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.seed = random.seed(seed)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
    "        x = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.array([random.random() for i in range(len(x))])\n",
    "        self.state = x + dx\n",
    "        return torch.tensor(self.state, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPGAgent:\n",
    "    def __init__(self, env, params, random_seed) -> None:\n",
    "        # grabbing parameters\n",
    "        self.gamma = params['gamma']\n",
    "        self.tau = params['tau']\n",
    "        self.actor_lr = params['actor_lr']\n",
    "        self.critic_lr = params['critic_lr']\n",
    "        self.batch_size = params['minibatch_size']\n",
    "        self.buffer_size = params['replay_buffer_size']\n",
    "        self.weight_decay = params['L2_weight_decay']\n",
    "\n",
    "        # setting random seeds\n",
    "        random.seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "        torch.cuda.manual_seed(random_seed) # setting for cuda if GPU available\n",
    "\n",
    "        # setting number of states and actions\n",
    "        self.num_states = env.observation_space.shape[0]\n",
    "        self.num_actions = env.action_space.shape[0]\n",
    "\n",
    "        # choose device\n",
    "        self.device = (\n",
    "            \"cuda\"\n",
    "            if torch.cuda.is_available()\n",
    "            else \"mps\"\n",
    "            if torch.backends.mps.is_available()\n",
    "            else \"cpu\"\n",
    "        )\n",
    "        print(f\"Using {self.device} device\")\n",
    "\n",
    "        # initialize critic network w target\n",
    "        self.critic = Critic(self.num_states, self.num_actions).to(self.device)\n",
    "        # summary(self.critic, input_size=(2))\n",
    "        # creating deepcopy to copy the network over to a target\n",
    "        self.critic_target = deepcopy(self.critic)\n",
    "        # define optimizer\n",
    "        self.critic_optim = Adam(self.critic.parameters(), lr=self.critic_lr, weight_decay=self.weight_decay)\n",
    "\n",
    "        # initialize actor network w target\n",
    "        self.actor = Actor(self.num_states, self.num_actions).to(self.device)\n",
    "        # summary(self.actor, input_size=(11,))\n",
    "        # creating deepcopy to copy the network over to a target\n",
    "        self.actor_target = deepcopy(self.actor)\n",
    "        # define optimizer\n",
    "        self.actor_optim = Adam(self.actor.parameters(), lr=self.actor_lr)\n",
    "\n",
    "        # OU noise for action selection\n",
    "        self.noise = OUNoise(self.num_actions, random_seed)\n",
    "\n",
    "        # initialize replay buffer and prepopulate\n",
    "        self.replay_buffer = ReplayBuffer(self.buffer_size)\n",
    "        # self.replay_buffer.prepopulate()\n",
    "\n",
    "    # get action with some noise\n",
    "    def get_action(self, env, state):\n",
    "        # convert to tensor to feed into network\n",
    "        state = torch.tensor(state, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        # set to eval mode to not track batch norm\n",
    "        self.actor.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            action = self.actor(state)\n",
    "            action += self.noise.sample()\n",
    "        self.actor.train()\n",
    "        \n",
    "        # copy to cpu if necessary\n",
    "        # convert to numpy for OpenAI step input\n",
    "        action = action.cpu().numpy()\n",
    "        action = np.clip(action,env.action_space.low,env.action_space.high)\n",
    "\n",
    "        return action\n",
    "    \n",
    "    # updates critic and actor\n",
    "    def update(self):\n",
    "        # sample batch\n",
    "        state_batch, action_batch, reward_batch, next_state_batch, dones_batch = self.replay_buffer.sample_random_minibatch(self.batch_size, self.device)\n",
    "\n",
    "        # calculate target batch\n",
    "        # with torch.no_grad():\n",
    "        target = self.calculate_target(reward_batch, next_state_batch, dones_batch)\n",
    "\n",
    "        # calculate q-value batch\n",
    "        q_val_batch = self.critic((state_batch, action_batch))\n",
    "\n",
    "        # updating critic: by minimizing loss\n",
    "        loss = nn.MSELoss()\n",
    "\n",
    "        self.critic_optim.zero_grad()\n",
    "        loss_val = loss(q_val_batch, target)\n",
    "        loss_val.backward()        \n",
    "        self.critic_optim.step()\n",
    "        \n",
    "        # updating actor: using critic to update actor\n",
    "        loss_actor = -self.critic((state_batch, self.actor(state_batch))) # TODO: should this be negative?\n",
    "        \n",
    "        self.actor.zero_grad()\n",
    "        loss_actor = torch.mean(loss_actor)\n",
    "        loss_actor.backward()\n",
    "        self.actor_optim.step()\n",
    "\n",
    "        # update target network weights\n",
    "        # update target critic\n",
    "        for target_param, param in zip(self.critic_target.parameters(), self.critic.parameters()):\n",
    "            target_param.data.copy_(\n",
    "                target_param.data * (1.0 - self.tau) + param.data * self.tau\n",
    "            )\n",
    "        \n",
    "        # update target actor\n",
    "        for target_param, param in zip(self.actor_target.parameters(), self.actor.parameters()):\n",
    "            target_param.data.copy_(\n",
    "                target_param.data * (1.0 - self.tau) + param.data * self.tau\n",
    "            )\n",
    "\n",
    "        return loss_actor.item()\n",
    "\n",
    "    def calculate_target(self, reward, next_state, dones):\n",
    "        next_action = self.actor_target(next_state)\n",
    "        target = reward + self.gamma*self.critic_target((next_state, next_action))*(1-dones)\n",
    "        return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 1:   0%|          | 1/2000 [00:01<36:44,  1.10s/it, Avg_Score=44.5, Episode_Score=44.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\tAverage Score: 44.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 101:   5%|▌         | 101/2000 [00:47<14:20,  2.21it/s, Avg_Score=39.2, Episode_Score=37.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 39.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 201:  10%|█         | 201/2000 [01:32<15:25,  1.94it/s, Avg_Score=38.7, Episode_Score=38.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 200\tAverage Score: 38.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 301:  15%|█▌        | 301/2000 [02:20<12:38,  2.24it/s, Avg_Score=38.7, Episode_Score=38.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 300\tAverage Score: 38.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 401:  20%|██        | 401/2000 [03:15<18:02,  1.48it/s, Avg_Score=38.9, Episode_Score=39]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 400\tAverage Score: 38.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 501:  25%|██▌       | 501/2000 [04:15<11:44,  2.13it/s, Avg_Score=38.9, Episode_Score=39.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 500\tAverage Score: 38.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 601:  30%|███       | 601/2000 [05:08<11:47,  1.98it/s, Avg_Score=38.7, Episode_Score=39.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 600\tAverage Score: 38.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 701:  35%|███▌      | 701/2000 [06:10<10:36,  2.04it/s, Avg_Score=38.7, Episode_Score=40.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 700\tAverage Score: 38.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 801:  40%|████      | 801/2000 [06:56<08:46,  2.28it/s, Avg_Score=38.6, Episode_Score=37.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 800\tAverage Score: 38.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 901:  45%|████▌     | 901/2000 [07:41<08:08,  2.25it/s, Avg_Score=38.6, Episode_Score=39.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 900\tAverage Score: 38.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 1001:  50%|█████     | 1001/2000 [08:26<07:28,  2.23it/s, Avg_Score=38.7, Episode_Score=39.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1000\tAverage Score: 38.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 1101:  55%|█████▌    | 1101/2000 [09:11<06:36,  2.27it/s, Avg_Score=38.4, Episode_Score=36]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1100\tAverage Score: 38.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 1201:  60%|██████    | 1201/2000 [09:56<05:48,  2.29it/s, Avg_Score=38.5, Episode_Score=36]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1200\tAverage Score: 38.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 1301:  65%|██████▌   | 1301/2000 [10:44<05:35,  2.09it/s, Avg_Score=38.6, Episode_Score=39.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1300\tAverage Score: 38.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 1401:  70%|███████   | 1401/2000 [11:29<04:21,  2.29it/s, Avg_Score=38.4, Episode_Score=37.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1400\tAverage Score: 38.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 1501:  75%|███████▌  | 1501/2000 [12:13<03:43,  2.23it/s, Avg_Score=38.4, Episode_Score=39]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1500\tAverage Score: 38.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 1601:  80%|████████  | 1601/2000 [12:58<02:54,  2.28it/s, Avg_Score=38.5, Episode_Score=37.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1600\tAverage Score: 38.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 1701:  85%|████████▌ | 1701/2000 [13:43<02:12,  2.26it/s, Avg_Score=38.6, Episode_Score=39.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1700\tAverage Score: 38.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 1801:  90%|█████████ | 1801/2000 [14:27<01:29,  2.22it/s, Avg_Score=38.4, Episode_Score=38.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1800\tAverage Score: 38.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 1901:  95%|█████████▌| 1901/2000 [15:12<00:44,  2.21it/s, Avg_Score=38.5, Episode_Score=37.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1900\tAverage Score: 38.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 2000: 100%|██████████| 2000/2000 [15:57<00:00,  2.09it/s, Avg_Score=38.6, Episode_Score=37.6]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# main loop\n",
    "def run_DDPG():\n",
    "    # initialize parameters\n",
    "    params = {'actor_lr': 0.0001,\n",
    "            'critic_lr': 0.001,\n",
    "            'tau': 0.0001,\n",
    "            'gamma': 0.99,\n",
    "            'minibatch_size': 64,\n",
    "            'replay_buffer_size': int(1e6),\n",
    "            'steps': 2_000,\n",
    "            'L2_weight_decay': 1e-2}\n",
    "\n",
    "    # grab cwd for model saving\n",
    "    cwd = os.getcwd()\n",
    "    \n",
    "    # create environment\n",
    "    env = gym.make('Hopper-v5', render_mode='human')\n",
    "\n",
    "    # ddpg object\n",
    "    ddpg = DDPGAgent(env, params, random_seed=10)\n",
    "\n",
    "    # keep track of loss\n",
    "    scores = []\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    loss = []\n",
    "\n",
    "    # loop through desired number of steps\n",
    "    with tqdm(range(params['steps']), desc=\"Episode\") as pbar:\n",
    "        for ep in pbar:\n",
    "            # reset env\n",
    "            state,_ = env.reset()\n",
    "\n",
    "            # initialize terminal state\n",
    "            done = False\n",
    "\n",
    "            # track cumulative reward\n",
    "            cumulative_reward = 0\n",
    "\n",
    "            # while environment isnt terminal\n",
    "            while not done:\n",
    "                # grab action with OU noise\n",
    "                action = ddpg.get_action(env, state)\n",
    "                # execute action in env\n",
    "                next_state, reward, done, truncate, _ = env.step(action)\n",
    "                # store in buffer\n",
    "                ddpg.replay_buffer.insert(state, action, reward, next_state, done)\n",
    "\n",
    "                # learn when buffer reaches batch size\n",
    "                if len(ddpg.replay_buffer.buffer) > ddpg.batch_size:\n",
    "                    loss_item = ddpg.update()\n",
    "                    loss.append(loss_item)\n",
    "\n",
    "                # update state\n",
    "                state = next_state\n",
    "\n",
    "                # update cumulative reward\n",
    "                cumulative_reward += reward\n",
    "\n",
    "            # append to running score and to score deque for average reward approximation\n",
    "            scores.append(cumulative_reward)\n",
    "            scores_deque.append(cumulative_reward)\n",
    "            pbar.set_description(f\"Episode {ep + 1}\")\n",
    "            pbar.set_postfix(Avg_Score=np.mean(scores_deque), Episode_Score=cumulative_reward)\n",
    "            # print('\\rEpisode {}\\tAverage Score: {:.2f}\\tEpisode score: {:.2f}'.format(ep, np.mean(scores_deque), cumulative_reward), end=\"\")\n",
    "            # save scores\n",
    "            if ep % 100 == 0:\n",
    "                torch.save(ddpg.actor.state_dict(), cwd+'/checkpoint_actor.pth')\n",
    "                torch.save(ddpg.critic.state_dict(), cwd+'/checkpoint_critic.pth')\n",
    "                print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(ep, np.mean(scores_deque)))   \n",
    "            \n",
    "            # reset env if done\n",
    "            env.reset()\n",
    "\n",
    "    \n",
    "    return scores, loss\n",
    "\n",
    "\n",
    "scores, loss = run_DDPG()\n",
    "\n",
    "plt.plot(np.arange(1,len(scores)+1), scores)\n",
    "plt.ylabel('Cumulative reward: ')\n",
    "plt.xlabel('Episodes')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run_DDPG() missing 2 required positional arguments: 'env_type' and 'render_mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 81\u001b[0m\n\u001b[0;32m     77\u001b[0m environments \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHopper-v5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHalfCheetah-v5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBipedalWalker-v3\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCartPole-v1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     78\u001b[0m render_mode \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 81\u001b[0m scores, loss \u001b[38;5;241m=\u001b[39m \u001b[43mrun_DDPG\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(scores)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), scores)\n\u001b[0;32m     84\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCumulative reward: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: run_DDPG() missing 2 required positional arguments: 'env_type' and 'render_mode'"
     ]
    }
   ],
   "source": [
    "\n",
    "# main loop\n",
    "def run_DDPG(env_type, mode):\n",
    "    # initialize parameters\n",
    "    params = {'actor_lr': 0.0001,\n",
    "            'critic_lr': 0.001,\n",
    "            'tau': 0.0001,\n",
    "            'gamma': 0.99,\n",
    "            'minibatch_size': 64,\n",
    "            'replay_buffer_size': int(1e6),\n",
    "            'steps': 2_000,\n",
    "            'L2_weight_decay': 1e-2}\n",
    "\n",
    "    # grab cwd for model saving\n",
    "    cwd = os.getcwd()\n",
    "    \n",
    "    # create environment\n",
    "    env = gym.make(env_type, render_mode=mode)\n",
    "\n",
    "    # ddpg object\n",
    "    ddpg = DDPGAgent(env, params, random_seed=10)\n",
    "\n",
    "    # keep track of loss\n",
    "    scores = []\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    loss = []\n",
    "\n",
    "    # loop through desired number of steps\n",
    "    with tqdm(range(params['steps']), desc=\"Episode\") as pbar:\n",
    "        for ep in pbar:\n",
    "            # reset env\n",
    "            state,_ = env.reset()\n",
    "\n",
    "            # initialize terminal state\n",
    "            done = False\n",
    "\n",
    "            # track cumulative reward\n",
    "            cumulative_reward = 0\n",
    "\n",
    "            # while environment isnt terminal\n",
    "            while not done:\n",
    "                # grab action with OU noise\n",
    "                action = ddpg.get_action(env, state)\n",
    "                # execute action in env\n",
    "                next_state, reward, done, truncate, _ = env.step(action)\n",
    "                # store in buffer\n",
    "                ddpg.replay_buffer.insert(state, action, reward, next_state, done)\n",
    "\n",
    "                # learn when buffer reaches batch size\n",
    "                if len(ddpg.replay_buffer.buffer) > ddpg.batch_size:\n",
    "                    loss_item = ddpg.update()\n",
    "                    loss.append(loss_item)\n",
    "\n",
    "                # update state\n",
    "                state = next_state\n",
    "\n",
    "                # update cumulative reward\n",
    "                cumulative_reward += reward\n",
    "\n",
    "            # append to running score and to score deque for average reward approximation\n",
    "            scores.append(cumulative_reward)\n",
    "            scores_deque.append(cumulative_reward)\n",
    "            pbar.set_description(f\"Episode {ep + 1}\")\n",
    "            pbar.set_postfix(Avg_Score=np.mean(scores_deque), Episode_Score=cumulative_reward)\n",
    "            # print('\\rEpisode {}\\tAverage Score: {:.2f}\\tEpisode score: {:.2f}'.format(ep, np.mean(scores_deque), cumulative_reward), end=\"\")\n",
    "            # save scores\n",
    "            if ep % 100 == 0:\n",
    "                torch.save(ddpg.actor.state_dict(), f'{cwd}/checkpoint_{env_type}_actor.pth')\n",
    "                torch.save(ddpg.critic.state_dict(), f'{cwd}/checkpoint_{env_type}_critic.pth')\n",
    "                print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(ep, np.mean(scores_deque)))   \n",
    "            \n",
    "            # reset env if done\n",
    "            env.reset()\n",
    "\n",
    "    \n",
    "    return scores, loss\n",
    "\n",
    "environments = ['Hopper-v5', 'HalfCheetah-v5', 'BipedalWalker-v3','CartPole-v1']\n",
    "render_mode = ['human','human','human','human']\n",
    "\n",
    "for i, env_type in enumerate(environments):\n",
    "    scores, loss = run_DDPG(env_type, render_mode[i])\n",
    "\n",
    "    plt.plot(np.arange(1,len(scores)+1), scores)\n",
    "    plt.ylabel('Cumulative reward: ')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# grab cwd for model saving\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# instantiate env\n",
    "env = gym.make('Hopper-v5', render_mode='human')\n",
    "\n",
    "# initialize parameters\n",
    "params = {'actor_lr': 0.0001,\n",
    "        'critic_lr': 0.001,\n",
    "        'tau': 0.001,\n",
    "        'gamma': 0.99,\n",
    "        'minibatch_size': 64,\n",
    "        'replay_buffer_size': int(10e6),\n",
    "        'steps': 100_000}\n",
    "\n",
    "ddpg = DDPGAgent(env, params, random_seed=10)\n",
    "\n",
    "ddpg.actor.load_state_dict(torch.load(cwd+'/checkpoint_actor.pth'))\n",
    "ddpg.critic.load_state_dict(torch.load(cwd+'/checkpoint_critic.pth'))\n",
    "\n",
    "state,_ = env.reset()  \n",
    "while True:\n",
    "    action = ddpg.get_action(env, state)\n",
    "    env.render()\n",
    "    next_state, reward, done, truncate, _ = env.step(action)\n",
    "    state = next_state\n",
    "    if done:\n",
    "        break\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "single_path = torch.tensor([1,2], = yes or no\n",
    "                           [2,4], = yes or no\n",
    "                           [3,6])\n",
    "\n",
    "three_paths = torch.tensor([[1,2],[2,4],[3,6]],\n",
    "                           [[1,2],[2,4],[3,6]],\n",
    "                           [[1,2],[2,4],[3,6]])  yes = 1, no = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
